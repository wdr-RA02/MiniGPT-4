{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mas-xie.haojie/codes_gzp/MiniGPT-4\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mas-xie.haojie/anaconda3/envs/openfla_py39_gao/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from minigpt4.common.config import Config\n",
    "\n",
    "from minigpt4.datasets.builders import *\n",
    "from minigpt4.models import *\n",
    "from minigpt4.processors import *\n",
    "from minigpt4.runners import *\n",
    "from minigpt4.tasks import *\n",
    "from minigpt4.common.registry import registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dummy dataset config \n",
    "dataset_config={\n",
    "    \"personality_captions\":{\n",
    "        \"vis_processor\":{\n",
    "            \"train\":{\n",
    "                \"name\": \"blip2_image_train\",\n",
    "                \"image_size\": 224\n",
    "            }\n",
    "        },\n",
    "        \"text_processor\":{\n",
    "            \"train\":{\n",
    "                \"name\": \"blip_caption\",\n",
    "                \"image_size\": 224\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "ds_config=Config.build_dataset_config({\"datasets\":dataset_config})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(datasets_config):\n",
    "    datasets=dict()\n",
    "    \n",
    "    for name in datasets_config:\n",
    "        dataset_config = datasets_config[name]\n",
    "\n",
    "        builder = registry.get_builder_class(name)(dataset_config)\n",
    "        dataset = builder.build_datasets()\n",
    "\n",
    "        dataset['train'].name = name\n",
    "        if 'sample_ratio' in dataset_config:\n",
    "            dataset['train'].sample_ratio = dataset_config.sample_ratio\n",
    "\n",
    "        datasets[name] = dataset\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datasets': {'personality_captions': {'data_type': 'images', 'build_info': {'storage': '/148Dataset/data-gao.zhenpeng/PCap/'}, 'vis_processor': {'train': {'name': 'blip2_image_train', 'image_size': 224}}, 'text_processor': {'train': {'name': 'blip_caption', 'image_size': 224}}}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=build_dataset(ds_config[\"datasets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[0.8355, 0.8501, 0.8501,  ..., 0.8355, 0.8355, 0.8355],\n",
       "          [0.8355, 0.8501, 0.8501,  ..., 0.8501, 0.8355, 0.8501],\n",
       "          [0.8355, 0.8501, 0.8501,  ..., 0.8501, 0.8355, 0.8355],\n",
       "          ...,\n",
       "          [1.0690, 1.0690, 1.0690,  ..., 0.9522, 0.9668, 0.9960],\n",
       "          [1.0544, 1.0544, 1.0544,  ..., 1.0544, 1.0398, 1.0398],\n",
       "          [1.0836, 1.0690, 1.0690,  ..., 1.0544, 1.0544, 1.0398]],\n",
       " \n",
       "         [[1.0243, 1.0393, 1.0393,  ..., 1.0243, 1.0243, 1.0093],\n",
       "          [1.0243, 1.0393, 1.0393,  ..., 1.0393, 1.0243, 1.0243],\n",
       "          [1.0243, 1.0393, 1.0393,  ..., 1.0393, 1.0243, 1.0243],\n",
       "          ...,\n",
       "          [1.2645, 1.2645, 1.2645,  ..., 1.1744, 1.1894, 1.1894],\n",
       "          [1.2495, 1.2495, 1.2495,  ..., 1.2495, 1.2344, 1.2344],\n",
       "          [1.2795, 1.2645, 1.2645,  ..., 1.2495, 1.2495, 1.2344]],\n",
       " \n",
       "         [[1.2074, 1.2216, 1.2216,  ..., 1.2074, 1.1932, 1.2074],\n",
       "          [1.2074, 1.2216, 1.2216,  ..., 1.2074, 1.1932, 1.2074],\n",
       "          [1.2074, 1.2216, 1.2216,  ..., 1.2074, 1.1932, 1.1932],\n",
       "          ...,\n",
       "          [1.4633, 1.4633, 1.4633,  ..., 1.3780, 1.3922, 1.3922],\n",
       "          [1.4491, 1.4491, 1.4491,  ..., 1.4491, 1.4349, 1.4349],\n",
       "          [1.4776, 1.4633, 1.4633,  ..., 1.4491, 1.4491, 1.4349]]]),\n",
       " 'answer': 'the snow will last as long as my sadness',\n",
       " 'personality': 'Intense',\n",
       " 'image_id': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcap=ds[\"personality_captions\"][\"train\"]\n",
    "\n",
    "pcap[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dl=DataLoader(pcap, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': tensor([[[[ 0.8647,  0.8647,  0.8647,  ...,  0.7333,  0.7479,  0.7333],\n",
      "          [ 0.8647,  0.8792,  0.8792,  ...,  0.7479,  0.7479,  0.7479],\n",
      "          [ 0.8647,  0.8647,  0.8792,  ...,  0.7625,  0.7479,  0.7625],\n",
      "          ...,\n",
      "          [ 1.0398,  1.0398,  1.0398,  ...,  1.0544,  1.0544,  1.0544],\n",
      "          [ 1.0252,  1.0106,  1.0106,  ...,  1.0398,  1.0398,  1.0398],\n",
      "          [ 1.0398,  1.0252,  1.0252,  ...,  1.0544,  1.0544,  1.0544]],\n",
      "\n",
      "         [[ 1.0544,  1.0544,  1.0544,  ...,  0.9643,  0.9793,  0.9643],\n",
      "          [ 1.0544,  1.0694,  1.0694,  ...,  0.9793,  0.9793,  0.9793],\n",
      "          [ 1.0544,  1.0544,  1.0694,  ...,  0.9943,  0.9793,  0.9943],\n",
      "          ...,\n",
      "          [ 1.2344,  1.2344,  1.2344,  ...,  1.2495,  1.2495,  1.2495],\n",
      "          [ 1.2194,  1.2194,  1.2194,  ...,  1.2344,  1.2344,  1.2344],\n",
      "          [ 1.2344,  1.2194,  1.2194,  ...,  1.2495,  1.2495,  1.2495]],\n",
      "\n",
      "         [[ 1.2358,  1.2358,  1.2358,  ...,  1.1363,  1.1505,  1.1363],\n",
      "          [ 1.2358,  1.2500,  1.2500,  ...,  1.1505,  1.1505,  1.1505],\n",
      "          [ 1.2358,  1.2358,  1.2500,  ...,  1.1647,  1.1505,  1.1647],\n",
      "          ...,\n",
      "          [ 1.4349,  1.4349,  1.4349,  ...,  1.4491,  1.4491,  1.4491],\n",
      "          [ 1.4207,  1.4207,  1.4207,  ...,  1.4349,  1.4349,  1.4349],\n",
      "          [ 1.4349,  1.4207,  1.4207,  ...,  1.4491,  1.4491,  1.4491]]],\n",
      "\n",
      "\n",
      "        [[[-0.5952, -0.5952, -0.5952,  ..., -1.1499, -1.1937, -1.1791],\n",
      "          [-0.5806, -0.5806, -0.5806,  ..., -1.1645, -1.1791, -1.1791],\n",
      "          [-0.5660, -0.5660, -0.5952,  ..., -1.1499, -1.1645, -1.1645],\n",
      "          ...,\n",
      "          [ 0.7917,  0.8063,  0.6749,  ..., -1.6463, -1.6609, -1.6901],\n",
      "          [ 0.8938,  0.8938,  0.7625,  ..., -1.6317, -1.6609, -1.6609],\n",
      "          [ 0.9230,  0.9084,  0.7479,  ..., -1.6171, -1.6463, -1.6609]],\n",
      "\n",
      "         [[ 0.2740,  0.2740,  0.2740,  ..., -0.1763, -0.1913, -0.2213],\n",
      "          [ 0.2890,  0.2890,  0.2890,  ..., -0.1763, -0.1763, -0.2063],\n",
      "          [ 0.3040,  0.3040,  0.2740,  ..., -0.1613, -0.1613, -0.1913],\n",
      "          ...,\n",
      "          [ 0.3640,  0.3940,  0.2589,  ..., -1.6170, -1.6320, -1.6621],\n",
      "          [ 0.4991,  0.4841,  0.3790,  ..., -1.6020, -1.6320, -1.6320],\n",
      "          [ 0.5291,  0.5441,  0.4240,  ..., -1.5870, -1.6170, -1.6320]],\n",
      "\n",
      "         [[ 1.1505,  1.1505,  1.1505,  ...,  0.7808,  0.7523,  0.7381],\n",
      "          [ 1.1647,  1.1647,  1.1647,  ...,  0.7808,  0.7666,  0.7523],\n",
      "          [ 1.1789,  1.1789,  1.1505,  ...,  0.7950,  0.7808,  0.7666],\n",
      "          ...,\n",
      "          [-0.3853, -0.4137, -0.5417,  ..., -1.2811, -1.2954, -1.3238],\n",
      "          [-0.3284, -0.3568, -0.4848,  ..., -1.2669, -1.2954, -1.2954],\n",
      "          [-0.3284, -0.3142, -0.4706,  ..., -1.2527, -1.2811, -1.2954]]],\n",
      "\n",
      "\n",
      "        [[[-0.2886, -0.2010, -0.1280,  ..., -1.0331, -1.0185, -1.0623],\n",
      "          [ 0.8938,  0.8792,  0.8792,  ..., -1.0185, -1.0185, -1.0769],\n",
      "          [ 1.5508,  1.5362,  1.5508,  ..., -1.0185, -1.0623, -1.0915],\n",
      "          ...,\n",
      "          [ 0.8063,  0.8647,  0.9376,  ...,  0.4851,  0.6457,  0.6311],\n",
      "          [ 0.8501,  0.8209,  0.9376,  ...,  0.5143,  0.5435,  0.4997],\n",
      "          [ 0.9376,  0.8792,  0.8647,  ...,  0.5581,  0.5289,  0.5289]],\n",
      "\n",
      "         [[ 0.1089,  0.1839,  0.2589,  ..., -0.9867, -1.0317, -1.0767],\n",
      "          [ 0.9643,  0.9943,  0.9793,  ..., -0.9867, -1.0167, -1.0918],\n",
      "          [ 1.6096,  1.6096,  1.6096,  ..., -1.0167, -1.0467, -1.0767],\n",
      "          ...,\n",
      "          [ 0.0188,  0.0488,  0.1539,  ..., -0.3864, -0.1913, -0.1463],\n",
      "          [ 0.0939,  0.0488,  0.1989,  ..., -0.3114, -0.2063, -0.2063],\n",
      "          [ 0.1389,  0.0789,  0.1089,  ..., -0.2513, -0.2813, -0.2663]],\n",
      "\n",
      "         [[ 0.5106,  0.6101,  0.6670,  ..., -0.7408, -0.7550, -0.8261],\n",
      "          [ 1.0367,  1.0510,  1.0510,  ..., -0.7408, -0.7692, -0.8403],\n",
      "          [ 1.6624,  1.6624,  1.6624,  ..., -0.7550, -0.7977, -0.8261],\n",
      "          ...,\n",
      "          [-0.3853, -0.3568, -0.2715,  ..., -0.6981, -0.5133, -0.4706],\n",
      "          [-0.2857, -0.3568, -0.2289,  ..., -0.6270, -0.5417, -0.5701],\n",
      "          [-0.3000, -0.3284, -0.3142,  ..., -0.5701, -0.5986, -0.5701]]]]), 'answer': ['the snow will last as long as my sadness', 'i love experiencing new cultures', 'look at that smooth easy catch of the ball like ballet'], 'personality': ['Intense', 'Adventurous', 'Mellow (Soothing, Sweet)'], 'image_id': tensor([0, 1, 2])}\n"
     ]
    }
   ],
   "source": [
    "for item in dl:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "eval_ds = \"../dataset/PCap/personality_captions/test.json\"\n",
    "ds = load_dataset(\"json\", data_files=eval_ds, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"inference_src.json\", \"r\") as f:\n",
    "    examples = json.load(f)\n",
    "\n",
    "# convert record to set\n",
    "keys = list(examples[0].keys())\n",
    "examples={k: [x[k] for x in examples] for k in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'personality': ['Stupid',\n",
       "  'Opinionated',\n",
       "  'Deep',\n",
       "  'Mystical',\n",
       "  'Grim',\n",
       "  'Calm',\n",
       "  'Lazy',\n",
       "  'Creative',\n",
       "  'Absentminded',\n",
       "  'Nihilistic',\n",
       "  'Destructive',\n",
       "  'Practical',\n",
       "  'Assertive',\n",
       "  'Practical',\n",
       "  'Aggressive',\n",
       "  'Cold',\n",
       "  'Exciting',\n",
       "  'Frivolous (Trivial, Silly)',\n",
       "  'Open'],\n",
       " 'image_hash': ['15cdd44cf6d73b8f0b64352372a91c1',\n",
       "  '2ed2094a52eb3579f4ef7c5e501db5',\n",
       "  'f07589c35e378e3043fd5f642513bb64',\n",
       "  'ac75942b5d6261354442cf502a2bb7dd',\n",
       "  '145c579124825a6fb82c5eee26d7a3ab',\n",
       "  'd9a74f6bc2d3cb0a517f1c6bd6dfdeb',\n",
       "  '837325523e1bd313536c18e63f3c252',\n",
       "  'f67bbbd0ffe146e76caad64022548aba',\n",
       "  'd039ee869ab8618bba1b78eb2e44bf3',\n",
       "  '13d6c33b85da7749aa62d966cc91d7',\n",
       "  '17bb5c2fddbd6ffcd4d35d43755cadd',\n",
       "  '17bb5c2fddbd6ffcd4d35d43755cadd',\n",
       "  'f08b5d8261d8363bba5ca5b0843037bf',\n",
       "  '6fc987ebf4fdea174621c361bd827fc6',\n",
       "  '594e9b352cf52b193dd824c9caa16a7',\n",
       "  'f2ed11c64f4cda6fd3fa35487f99d412',\n",
       "  'dfcc3c611e334a37e8b2f3475b4a946',\n",
       "  '2641f7424531f8bdbf241bc9c9a631f',\n",
       "  '1ceb484e59e9fa56971780d0f87ceb'],\n",
       " 'reference': ['why do cones even exist',\n",
       "  'I would never wear that top with those pants.',\n",
       "  'This was found in a glacier.',\n",
       "  \"Cloudy ward evenings in natures' golden hue.\",\n",
       "  'You could use any of these to strangle someone.',\n",
       "  'Cool picture man.',\n",
       "  'I could sit under that tree all day and not do a thjng',\n",
       "  'Just a little higher there and a little more base and it will create the sound',\n",
       "  'I would jump through this.',\n",
       "  'THIS BOY LOOKS THE SAME IN BOTH PICTURES BUT IS A TERRIBLE SERIAL KILLER.',\n",
       "  \"I'm no pro, but he is definitely holding that bat wrong.\",\n",
       "  'no/idea',\n",
       "  'consider this place owned by the state ',\n",
       "  'I totally could go without the Nutella.',\n",
       "  'I bet they are discussing about pointless stuff. I HATE these people!',\n",
       "  \"Those chairs look uncomfortable. You couldn't pay me to sit in them.\",\n",
       "  'My painting one first prize',\n",
       "  'WHERE YOU CAN GO DOWNTOWN',\n",
       "  'open the heart to share with others']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mas-xie.haojie/anaconda3/envs/openfla_py39_gao/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../../minigpt4_misc/vicuna-7b/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 263]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"a\", add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openfla_py39_gao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
